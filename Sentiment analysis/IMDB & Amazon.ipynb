{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import nltk\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'Round1_Problem1-of-2_Dataset_amazon_cells_labelled.txt', 'Round1_Problem1-of-2_Dataset_imdb_labelled.txt', 'Round1_Problem1-of-2_Problem.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"Desktop/Language_1/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Desktop/Language_1/Round1_Problem1-of-2_Dataset_amazon_cells_labelled.txt', sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('Desktop/Language_1/Round1_Problem1-of-2_Dataset_imdb_labelled.txt', sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  A very, very, very slow-moving, aimless movie ...  0\n",
       "1  Not sure who was more lost - the flat characte...  0\n",
       "2  Attempting artiness with black & white and cle...  0\n",
       "3       Very little music or anything to speak of.    0\n",
       "4  The best scene in the movie was when Gerardo i...  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (748, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape,data2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data3=pd.concat(([data1,data2]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.rename(index={0:'Serial no'}, columns={0:'Text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.rename(index={0:'Serial no'}, columns={1:'Sentiment'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial no    So there is no way for me to plug it in here i...\n",
       "1                                  Good case, Excellent value.\n",
       "2                                       Great for the jawbone.\n",
       "3            Tied to charger for conversations lasting more...\n",
       "4                                            The mic is great.\n",
       "5            I have to jiggle the plug to get it to line up...\n",
       "6            If you have several dozen or several hundred c...\n",
       "7                  If you are Razr owner...you must have this!\n",
       "8                          Needless to say, I wasted my money.\n",
       "9                             What a waste of money and time!.\n",
       "10                             And the sound quality is great.\n",
       "11           He was very impressed when going from the orig...\n",
       "12           If the two were seperated by a mere 5+ ft I st...\n",
       "13                                    Very good quality though\n",
       "14           The design is very odd, as the ear \"clip\" is n...\n",
       "15           Highly recommend for any one who has a blue to...\n",
       "16                         I advise EVERYONE DO NOT BE FOOLED!\n",
       "17                                            So Far So Good!.\n",
       "18                                               Works great!.\n",
       "19           It clicks into place in a way that makes you w...\n",
       "20           I went on Motorola's website and followed all ...\n",
       "21           I bought this to use with my Kindle Fire and a...\n",
       "22                    The commercials are the most misleading.\n",
       "23           I have yet to run this new battery below two b...\n",
       "24           I bought it for my mother and she had a proble...\n",
       "25                        Great Pocket PC / phone combination.\n",
       "26           I've owned this phone for 7 months now and can...\n",
       "27           I didn't think that the instructions provided ...\n",
       "28           People couldnt hear me talk and I had to pull ...\n",
       "29                                        Doesn't hold charge.\n",
       "                                   ...                        \n",
       "718          Enough can not be said of the remarkable anima...\n",
       "719          The art style has the appearance of crayon/pen...\n",
       "720          If you act in such a film, you should be glad ...\n",
       "721          This one wants to surf on the small wave of sp...\n",
       "722          If you haven't choked in your own vomit by the...\n",
       "723          Still, it makes up for all of this with a supe...\n",
       "724          Just consider the excellent story, solid actin...\n",
       "725          Instead, we got a bore fest about a whiny, spo...\n",
       "726          Then I watched it again two Sundays ago (March...\n",
       "727               It is a very well acted and done TV Movie.  \n",
       "728          Judith Light is one of my favorite actresses a...\n",
       "729                        I keep watching it over and over.  \n",
       "730                         It's a sad movie, but very good.  \n",
       "731          If you have not seen this movie, I definitely ...\n",
       "732                   She is as lovely as usual, this cutie!  \n",
       "733          Still it's quite interesting and entertaining ...\n",
       "734                            ;) Recommend with confidence!  \n",
       "735          This movie is well-balanced with comedy and dr...\n",
       "736          It was a riot to see Hugo Weaving play a sex-o...\n",
       "737          :) Anyway, the plot flowed smoothly and the ma...\n",
       "738          The opening sequence of this gem is a classic,...\n",
       "739                     Fans of the genre will be in heaven.  \n",
       "740                        Lange had become a great actress.  \n",
       "741                        It looked like a wonderful story.  \n",
       "742                    I never walked out of a movie faster.  \n",
       "743          I just got bored watching Jessice Lange take h...\n",
       "744          Unfortunately, any virtue in this film's produ...\n",
       "745                           In a word, it is embarrassing.  \n",
       "746                                       Exceptionally bad!  \n",
       "747          All in all its an insult to one's intelligence...\n",
       "Name: Text, Length: 1748, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing major stopwords\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "def pre_process(text):\n",
    "    clean_text=[char for char in text if char not in string.punctuation]\n",
    "    clean_text=\"\".join(clean_text)\n",
    "    clean_text=[words for words in clean_text.split() if words not in stopwords.words('english')]\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove tags\n",
    "def remove_tags(Text):\n",
    "    return ''.join(xml.etree.ElementTree.fromstring(text).itertext())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing website link\n",
    "df = pd.DataFrame({'text':['www.xyz.com','https://www.xyz.com','http://Google.com']})\n",
    "data3['Text'] = data3['Text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Sentiment'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation\n",
    "def non_punct(df):\n",
    "\n",
    "    data3['Text'] = data3['Text'].str.replace('[^\\w\\s]')                               \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series.apply 0.7816088199615479\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "start = time.time()\n",
    "data3[\"Text\"] = data3[\"Text\"].apply(nltk.word_tokenize)\n",
    "print( \"series.apply\", (time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "import nltk\n",
    "import pandas as pd\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(Text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(Text)]\n",
    "    data3 = pd.DataFrame([ 'Blessing->bless'], columns=['Text'])\n",
    "    print(df)\n",
    "    data3.Text.apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "x = CountVectorizer(analyzer=pre_process).fit(data3['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tiger\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4712"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 572)\t1\n",
      "  (0, 1011)\t1\n",
      "  (0, 1141)\t1\n",
      "  (0, 1890)\t1\n",
      "  (0, 2562)\t1\n",
      "  (0, 3476)\t1\n",
      "  (0, 4465)\t1\n",
      "  (0, 4586)\t1\n",
      "  (1, 424)\t1\n",
      "  (1, 501)\t1\n",
      "  (1, 1656)\t1\n",
      "  (1, 4512)\t1\n",
      "  (2, 507)\t1\n",
      "  (2, 2864)\t1\n",
      "  (3, 44)\t1\n",
      "  (3, 833)\t1\n",
      "  (3, 1105)\t1\n",
      "  (3, 1700)\t1\n",
      "  (3, 1889)\t1\n",
      "  (3, 2926)\t1\n",
      "  (3, 3147)\t1\n",
      "  (4, 1088)\t1\n",
      "  (4, 2586)\t1\n",
      "  (4, 3131)\t1\n",
      "  (5, 572)\t1\n",
      "  :\t:\n",
      "  (1743, 1563)\t1\n",
      "  (1743, 1768)\t1\n",
      "  (1743, 2576)\t1\n",
      "  (1743, 4222)\t1\n",
      "  (1743, 4583)\t1\n",
      "  (1744, 1149)\t1\n",
      "  (1744, 2408)\t1\n",
      "  (1744, 3025)\t1\n",
      "  (1744, 3555)\t1\n",
      "  (1744, 3683)\t1\n",
      "  (1744, 3839)\t1\n",
      "  (1744, 4537)\t1\n",
      "  (1744, 4661)\t1\n",
      "  (1745, 589)\t1\n",
      "  (1745, 2208)\t1\n",
      "  (1745, 4658)\t1\n",
      "  (1746, 426)\t1\n",
      "  (1746, 1464)\t1\n",
      "  (1747, 111)\t1\n",
      "  (1747, 2718)\t1\n",
      "  (1747, 2822)\t1\n",
      "  (1747, 2826)\t1\n",
      "  (1747, 3165)\t1\n",
      "  (1747, 3309)\t1\n",
      "  (1747, 4577)\t1\n"
     ]
    }
   ],
   "source": [
    "x = x.transform(data3['Text'])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1748, 4712)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data3['Sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1223, 4712)\n",
      "(1223,)\n",
      "(525, 4712)\n",
      "(525,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb=MultinomialNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=nb.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY : 0.7657142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"ACCURACY : \"+str(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183  87]\n",
      " [ 36 219]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75       270\n",
      "           1       0.72      0.86      0.78       255\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       525\n",
      "   macro avg       0.78      0.77      0.76       525\n",
      "weighted avg       0.78      0.77      0.76       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test='I will like this charger forever'\n",
    "x = CountVectorizer(analyzer=pre_process).fit(data3['Text'])\n",
    "test=x.transform([test])\n",
    "nb.predict(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test='Belt is not good quality... not worth for money'\n",
    "x = CountVectorizer(analyzer=pre_process).fit(data3['Text'])\n",
    "test=x.transform([test])\n",
    "nb.predict(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Tiger\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred).to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
